\documentclass[UTF8]{ctexart}
\usepackage{color}
\usepackage{algorithm}  
\usepackage{algpseudocode}  
\usepackage{amsthm,amsmath,amssymb}
\usepackage{mathrsfs}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage{tikz}
\usepackage{verbatim}
\usetikzlibrary{trees}

\title{有关BP神经网络的分析及优化改进研究}
\author{余畅 \\ 2019091621002， 信息与软件工程学院}
\begin{document}
\maketitle

\section{摘要}
\textbf{关键词：人工神经网络，BP算法，最速下降法，算法改进} \par
人工神经网络（Artificial Neural Network，ANN ）是20世纪80 年代以来人工智能领域兴起的研究热点。人工神经网络所代表的，即是对人脑的神经元进行不同层次的抽象，使用不同的连接方法组成不同的网络，本质上来说就是一种\textbf{运算模型}。最近十多年来，人工神经网络的研究工作不断深入，在模式识别、预测估计、自动控制等领域都取得了较大的发展。随着研究的不断深入，卷积神经网络，图神经网络，细胞神经网络等算法相继出现。但无法忽视的是，\textbf{BP神经网络}虽然出现时间较早，算法构造相对简单，但其作为人工智能神经网络中的典型算法，其本身具有很强的非线性分类能力，在解决非线性的问题上能力突出。此外，BP神经网络的网络拓扑结构简单，因而具有较高的误差精度；其算法简单，可操作性强，易于编程实现。这些优点都使得BP神经网络成为智能领域的重要算法之一。 \par
然而标准的BP神经网络算法既有其优点，也有其局限性：标准BP神经网络使用最速下降法进行优化，收敛速度慢且很容易陷入局部最小点，产生学习能力不足的问题；标准BP神经网络的隐含层难以通过标准的方法给出所需的层数和每层神经元的节点数，容易产生过拟合和欠拟合的问题；标准BP神经网络是有监督的学习算法，其每一个输入模式都必须知道期望输出以及误差精度。这些缺陷导致标准BP神经网络算法参数过多，经验性较强，算法的学习能力依赖于不断地调参和试错。 \par
本文章旨在介绍标准BP算法的基本原理，结合其不同的缺点总结相应的改进方案，并基于已有的改进方案，提出另一种改进方法。

\section{序言}
\subsection{背景}
人工神经网络是为了进行信息处理而建立的一种数学模型。它被称为神经网络是因为它是在现代神经科学研究成果的基础上提出的，通过一个个人工神经元模拟人类人类大脑神经突触连结形成的网络结构。它可以模仿人脑神经系统对外界信号接受、处理、储存的过程，具有强大的信息处理的能力。 \par
19世纪40年代初，心理学家Mcculloch和数学家Pitts从信息处理和数学建模的角度出发，通过研究信号在神经元之间进行传递的机制，提出了神经元的MP数学模型，随后无导师学习、感知器模型、反向传播算法、最小均方规则、模拟退火算法、竞争学习等等理论和算法也相继被提出。通过这些学习模型，神经网络的学习结构，处理各类信息的能力等都得到了改善，并得到了极大的发展：其具有非线性的映射能力，擅于从输入和输出信号中寻找规律，不需要进行精确的建模，从软硬件层面都易于实现，而且具有并行能力。人工神经网络解决问题的普适性和鲁棒性，使得其在模式识别，人工视觉，文本翻译，信号处理等领域展现出强大的能力。 \par
\subsection{BP神经网络简史}
1985年Rumelhart在\textbf{误差反向传播理论}的基础上提出反向传播（Back-Propagation）学习算法，即BP神经网络算法。BP神经网络构建在多层前馈网络的基础上，由输入、输出、隐含层组成。输入信号首先通过各个神经元激活函数的作用，在各层神经元之间层层传递，最终完成正向传播；接着根据正向传播得到的误差信号，BP神经网络利用梯度下降法进行有导师式的反向传播学习；在正向、反向学习反复不断进行的过程中，误差信号最终收敛到一个最小值。1988年Cybenko指出，当各个节点（即神经元）均采用Sigmoid型函数时，一个隐含层就足以实现任意的判决分类问题，两个隐含层则足以表示输入图形的任意输出函数。这反映出BP神经网络具有强大的数据识别和模拟能力，尤其是在解决非线性系统的问题的领域，主要有：模式识别、智能控制、图像识别、优化计算等等。 \par
\subsection{BP神经网络缺陷}
随着BP神经网络在多领域的广泛应用，BP算法自身存在的诸多问题也逐渐暴露出来：BP神经网络的收敛速度慢，导致学习的时间过长；学习过程中容易陷入局部极小值；网络的泛化能力差；构建网络结构缺乏统一原则等。缺陷产生的直接原因是BP神经网络自身的算法不完善，产生了算法精度差的直接后果，影响网络的学习速度，限制了网络的广泛运用。自从BP算法被提出之后，对于它的改进工作就一直在进行。本文希望能通过分析BP算法的原理之后，针对BP算法的不足，借鉴前人的一些实际运用的改进经验，进一步提出改进BP算法的新思路。

\section{BP神经网络的原理及方法}

\subsection{BP神经网络的基本原理}

作为人工神经网络中应用广泛的算法模型，BP神经网络具有完备的理论体系和学习机制。BP神经网络模仿人脑神经元对外部激励信号的反应过程，建立多层的感知器模型，并且不断地重复迭代信号的正向传播和误差的反向调节，通过这样多次的迭代学习，网络将自动调整收敛到最终的结果。

\subsection{BP神经网络的理论基础}

BP神经网络的结构基础是\textbf{单层感知器模型}，作为神经网络中的一个最小的单元，它试图模拟人脑神经元记忆、学习和认知的过程。现代生理学研究证明，人脑的大脑皮层的神经细胞数量约在10亿的级别上，而大约有60万亿左右的神经突触以及连接体。单一的生物神经元并不能完成人类复杂的反射活动，但也不是简单粗暴的将多个生物神经元在功能上简单叠加就可以做到，事实上，人类的大脑是\textbf{一系列神经元进行大量非线性动态数据处理而形成的信息处理系统}。相似的，人工神经元采用阈值激活函数（Activation function）将一组输入向量映射到一个 $0$ 或是 $1$ 的目标输出。人脑的神经元形态各异，但是具有共性的部分，主要包括四个部分：细胞体、树突、轴突和突触。树突是细胞向外延伸出的数量较多的较短分支，可以接受其他神经元提供的脉冲信息，相当于细胞的输入端；轴突是细胞单一的向外伸出的最长分支，信息通过此传输到其他的神经元，相当于细胞的输出端。总结来说，\textbf{信息流从树突出发，经过细胞体，最终从轴突传出}。 \par

通常来看，构成BP神经元模型的三个要素是：

\begin{itemize}
\item [1)]
具有一组突触或连接。常用 $w_{ij}$ 表示神经元 $i$ 和神经元 $j$ 之间的连接强度（权值）。和生物神经元一样，这个权值可正可负。若正，则表示突触起到激活的作用；反之为负，则起到抑制的作用。如果突触 $j$ 接受到了强度为 $s_i$ 的输入信号，则信号值会和突触 $j$ 上的权重 $w_{ji}$ 相乘。
\item [2)]
具有反映生物神经元时空整合功能的输入信号累加器。即将输入权值向量通过不同的权重累加映射为实数，可表达为 $R_j = \sum_{i=1}^{n}w_{ji}x_{i}$
\item [3)]
具有一个激活函数用于限制神经元输出。激活函数通常将输出范围限制在 $[-1,1]$ 或者 $[0,1]$ 的实数域中。
\end{itemize}

1943年心理学家 McCelland 和数学家 W. Pitts 通过分析人脑神经系统结构，在此研究的基础上，提出了MP模型。1986年以Rumelhart，Williams，Hinton，McCelland等科学家为首的科学家小组提出了BP（Back Propagation）神经网络，其定义是由反向传播误差算法训练出的多层前馈网络。总结来看，BP神经元模型就是MP模型不断改进之后的结果。BP神经网络可以灵活地学习和储存输入和输出之间的映射关系而无需在学习和储存前事先通过某种数学方程或者算法描述出这种映射关系。最速下降法是BP神经网络的学习算法，网络在正向传播之后计算误差，通过将误差反向传播的方式调整网络的连接权系数和阈值的信息，最终使得神经网络的平方误差最小，达到期望要求。 \par

BP（Back Propagation）神经网络的基本原理是把一个输入矢量（由训练样本提供）经过隐含层的一系列变换，然后得到一个输出矢量，从而实现输入数据与输出数据间的一个映射关系。输入信息的正向传播，以及输出误差的反向传播，构成了BP网络的信息循环。BP算法根据输出误差来修改各神经元连接的连接权系数，其目的是使输出误差达到期望的范围内。BP网络是一种有导师学习网络，因为，它需要实际输出与期望输出之间的误差来确定是否要修改神经元的连接权系数。其中，期望输出便是该网络意义上的“导师”。BP网络具有对称性的网络结构。在BP网络中，输出端的每一个处理单元基本上都具有一个相同的激励函数。

\subsubsection{BP神经网络的拓扑结构}

BP神经网络模型的拓扑结构可以被划分为三层：输入层（Input Layer），输出层（Output Layer）和隐含层（Hide Layer）。其中输入层和输出层是必要的，隐含层可以划入输入层或者去掉。和生物神经元类似，拓扑层中的每一层都
由大量能够执行并行运算的简单神经元组成。理论上讲每一层中的单个神经元的运算都是并行进行的，所以神经网络的复杂度只和层数有关，但由于计算机算力的限制，实际情况下人工神经元的并行性不可能达到生物神经元的并行性。BP神经网络是一个前馈网络，因此它具有前馈网络所具有的特性，即\textbf{相邻两层之间的全部神经元都进行相互连接，而处于同一层的神经元之间无法连接}。虽然单一神经元的结构简单且功能有限，但是一旦将数量庞大神经元构建为一定连接方式的网络系统，它们之间相互交互和传递，记录数据，就可以解决许多复杂度问题。神经网络能够对信息进行并行协同处理并行协同处理并分布式储存信息，由此可以看出它是一种非线性动力学系统，上面描述的就是这种系统的特点。 \par

在BP网络的拓扑结构中，网络层数以及输入节点与输出节点的节点数目都是待解决问题本身和问题规模来确定的，最关键的是对隐含层的层数与隐含层中节点数目的确定。 \par

隐含层是神经网络中一层或多层位于输入层和输出层之间的中间层，可以被看作是输入模式在神经网络中的一种内部表示。它的作用是把一类输入模式中与其他类输入模式不相同的特征进行抽取，并且将抽出的那部分特征再次传递给输出层，然后由输出层对其做出判断。隐含层产生作用的过程，即抽取输入模式特征的过程，实际上就是实现了\textbf{输入层与隐含层的连接权系数的调整过程}，是一个“自组织化的过程”。因此，在网络的学习训练过程中，层与层间的连接权系数起着输入层到输出层之间桥梁的作用，即用于“特征的传递”。

\subsubsection{BP神经网络的学习过程}

BP神经网络的学习算法实际上就是采用最速下降法对误差函数求极小值（而不是最小值）的算法，它通过反复迭代的训练过程，通过反向传播误差来修改连接权系数，它是沿着输出误差函数的负梯度方向对其进行改变。理想状态下，算法应使误差函数最终收敛到该函数的最小点，但由于梯度只是函数的局部特征，如果没有控制正确的算法步长（即学习速率，算法最后往往收敛到的是函数的极小值而不是最小值。通常情况下，需要随机多次选取不同的初始值以得到最好的结果。

\subsection{BP神经网络的基本原理}

\subsubsection{BP神经元原理}

BP神经元和BP神经网络的关系就像蜂群和每只蜜蜂的关系一样。很难说每只蜜蜂是不可或缺的，或者说会对整个群体产生重大影响，但是其构成的整体就产生了质变的效果，BP神经元是构成BP神经网络的基本单元。因此，如果要了解BP神经网络的基本原理，那么从BP神经元的基本原理入手将会产生更好的效果。 \par

和人工神经元类似，BP神经元主要模仿了生物神经元的三个最基本但是是最重要的特征：加权、求和和转移。令 $x_1,x_2,...,x_i,...,x_n$ 分别代表来自神经元 $1,2,...,i,...,n$ 的输入；$w_{j1},w_{j2},...,w_{jn}$ 这一向量表示的是网络前一层神经元 $1,2,...,i,...,n$ 与这一层的第 $j$ 个神经元连接权系数；$b_j$ 为阈值；$f(.)$ 为传递函数； $y_j$ 为第 $j$ 个神经元的输出。可以推知 BP 网络在第 $j$ 个神经元的净输入值可以表示为：

\begin{equation} 
S_j = \sum_{i=1}^n w_{ji} \cdot x_i + b_j = W_j X + b_j
\end{equation}

其中，$X = [x_1x2...x_i...x_n]^T$，$W=[w_{j1}w_{j2}...w_{ji}...w_{jn}]$。如果让 $x_0=1$，$w_{j0}=b_j$，即令 $X$ 及 $W_j$ 包括 $x_0$ 和 $w_{j0}$，则：

\begin{equation} 
X=[x_0x_1x_2...x_i...x_n]^T,W=[w_{j0}w_{j1}w_{j2}...w_{ji}...w_{jn}]
\end{equation}

那么，$j$ 节点的净输入 $S_j$ 可以用下面的公式来表示：

\begin{equation} 
S_j = \sum_{i=0}^n w_{ji} \cdot x_i = W_j X
\end{equation}

净输入 $S_j$ 通过激励函数（Transfer Function）$f(.)$ 之后，就可以得到第 $j$ 个神经元的净输出 $y_j$：

\begin{equation} 
y_j = f(S_j) = f(\sum_{i=0}^n w_{ji} \cdot x_i) = f(W_j X)
\end{equation}

在上式中，$f(.)$ 是一个单调递增的有界函数，由于其存在上界，所以神经元细胞所传递的信号不会被无限放大。

\subsubsection{BP网络算法原理}

BP算法能够比较系统地解决多层前馈网络中隐含层神经元地连接权系数的许多学习问题。 \par

(1) 正向传播 \par

前文已对BP算法的正向传播进行了简单的描述。关于BP算法的正向传播，其传播方向为先从输入层到隐含层，再通过隐含层传输到输出层，并且每一层的神经元状态仅仅影响到它下一层的神经元，同层的神经元则不会相互影响。如果在输出层得到的实际输出不能满足我们所期望的输出，那么BP算法就会转到误差的反向传播过程中。正向传播和反向传播这两个过程是轮流进行的。 \par

不妨设BP网络的输入层、隐含层和输出层三层的节点个数分别记为:$n$、$q$、$m$；每个神经元节点（单元）均使用Sigmoid型函数作为激励函数；并用 $v_{ki}$ 来表示输入层和隐含层之间的连接权系数；而用 $w_{jk}$ 来表示隐含层与输出层之间的连接权系数。假设隐含层和输出层的激励函数分别为 $f_1(.)$，$f2_(.)$，那么当输入为 $w_i,i=0,1,...,n$ 时，隐含层神经元节点的输出则为：

\begin{equation} 
c_k = f_1(\sum_{i=0}^{n} v_{ki} \cdot x_i) k = 1,2,...,q
\end{equation}

输出端的神经元节点的输出方程为：

\begin{equation} 
y_j = f_2(\sum_{k=0}^{q} w_{jk} \cdot c_k) j = 1,2,...,m
\end{equation}

根据上述两个公式，我们就可以得到一次BP神经网络的近似输出，也就是说，通过以上操作可以完成一个非线性的近似映射，这个映射是由 $n$ 维空间向量向 $m$ 维空间向量的一个映射。

(2) 反向传播 \par

要学习BP网络的反向传播，首先要定义该网络的误差函数。接下来就先确定一个误差函数。 \par

首先输入 $P$ 个学习样本，分别用 $x^1,x^2,...,x^p$ 来表示这些样本。把这些学习样本输入到神经网络中后，我们便可以得到一个实际输出$y_j^p(j=1,2,...,m)$。如果把平方型误差函数作为该神经网络的目标函数，那么再计算以后我们便可以得到第 $p$ 个学习样本的误差 $E_p$：

\begin{equation} 
E_p=\frac{1}{2} \sum_{j=1}^{m}  (t_{j}^{p} - y_{j}^{p})^2
\end{equation}

其中，$t_{j}^{p}$ 为我们定义的一个期望输出。对于这 $P$ 个学习样本来说，它们的全局误差计算公式如下：

\begin{equation} 
E=\frac{1}{2} \sum_{p=1}^{P} \sum_{j=1}^{m}  (t_{j}^{p} - y_{j}^{p})^2 = \sum_{p=1}^{P} E_p
\end{equation}

计算BP网络中各个样本的误差的目的主要就是为了改变网络权值，使其更加适合、更能满足网络需求，并且使误差减小到精度要求。那么误差的计算是如何去改变权值的呢？下面将对这个过程做出详细的描述。 \par

如果利用累计误差方法来计算BP算法的误差，并用此来调整连接权系数 $w_{jk}$，那么就可以很大程度上减小全局误差 $E$，其计算公式如下：

\begin{equation} 
\Delta w_{jk} = - \eta \frac{\partial E}{\partial w_{jk}} = - \eta \frac{\partial}{\partial w_{jk}} \left(\sum_{p=1}^{P} E_p\right) = \sum_{p=1}^{P} \left(- \eta \frac{\partial E_p}{\partial w_{jk}}\right)
\end{equation}

其中，$0<\eta<1$，它通常被称为学习速率。 \par

误差信号可定义为：

\begin{equation}
\delta_{yj} = - \frac{\partial E_p}{\partial S_j} = - \frac{\partial E_p}{\partial y_j} \cdot \frac{\partial y_j}{\partial S_j}
\end{equation}

对上述公式中的第一项做如下的分析：

\begin{equation}
\frac{\partial E_p}{\partial y_j} = \frac{\partial}{\partial y_j} [\frac{1}{2} \sum_{j=1} ^ {m} (t_{j}^{p} - y_{j}^{p})^2] = - \sum_{j=1}^{m} (t_{j}^{p} - y_{j}^{p})
\end{equation}

上式中的第二项则可被分析为：

\begin{equation}
\frac{\partial y_j}{\partial S_j} = f_2^{'}(S_j)
\end{equation}

根据上式可知这一项是输出层激活函数的偏微分。 \par

所以误差可以用下式表示： \par

\begin{equation}
\delta_{yj} = \sum_{j=1}^{m} (t_{j}^{p} - y_{j}^{p}) \cdot f_2^{'}(S_j)
\end{equation}

根据链式法则可以得到：

\begin{equation}
\frac{\partial E}{\partial w_{jk}} = \frac{\partial E}{\partial S_j} \cdot \frac{\partial S_j}{\partial w_{jk}} = - \delta_{yj} \cdot c_k = - \sum_{j=1}^{m} (t_{j}^{p} - y_{j}^{p}) \cdot f_2^{'}(S_j) \cdot c_k
\end{equation}

综上所述，我们可以使用下公式来表示输出层每一个神经元的连接权系数的调整：

\begin{equation}
\Delta w_{jk} = \sum_{p=1}^{P} \sum_{j=1}^{m} \eta (t_{j}^{p} - y_{j}^{p}) \cdot f_2^{'}(S_j) \cdot c_k
\end{equation}

上面介绍了输出层各神经元的权值调整，接下来介绍隐含层的权值是如何变化的。 \par

隐含层权值变化与全局误差的关系可以用下式表示：

\begin{equation}
\Delta v_{ki} = - \eta \frac{\partial E}{\partial v_{ki}} = - \eta \frac{\partial}{\partial v_{ki}} (\sum_{p=1}^{P} E_p) = \sum_{p=1}^{P} (- \eta \frac{\partial E}{\partial v_{ki}})
\end{equation}

信号误差可以定义为：

\begin{equation}
\delta_{ck} = -\frac{\partial E_p}{\partial S_k} = -\frac{\partial E_p}{\partial c_k} \cdot \frac{\partial c_k}{\partial S_k}
\end{equation}

上述公式中的第一项可以做如下分析：

\begin{equation}
\frac{\partial E_p}{\partial c_k} = \frac{\partial}{\partial c_k} [\frac{1}{2} \sum_{j=1}^{m}  (t_{j}^{p} - y_{j}^{p})^2] = - \sum_{j=1}^{m} (t_{j}^{p} - y_{j}^{p}) \frac{\partial y_j}{\partial c_k}
\end{equation}

根据链式求导法则，我们可以得到：

\begin{equation}
\frac{\partial y_j}{\partial c_k} = \frac{\partial y_j}{\partial S_j} \cdot \frac{\partial S_j}{\partial c_k} = f_{2}^{'}(S_j)w_{jk}
\end{equation}

对于公式 $(17)$ 的第二项，则有如下分析：

\begin{equation}
\frac{\partial c_k}{\partial S_k} = f_{1}^{'}(S_k)
\end{equation}

很明显，第二项为隐含层激励函数的偏微分。 \par

因此，隐含层权值变化可以表示为：

\begin{equation}
\delta_{ck} = \sum_{j=1}^{m} (t_{j}^{p} - y_{j}^{p}) \cdot f_2^{'}(S_j) \cdot w_{jk} \cdot f_1^{'}(S_k)
\end{equation}

根据链式求导法则，我们可以得到：

\begin{equation}
\frac{\partial E_p}{\partial v_{ki}} = \frac{\partial E_p}{\partial S_k} \cdot \frac{\partial S_k}{\partial v_{ki}} = - \delta_{ck} \cdot x_i = - \sum_{j=1}^{m} (t_{j}^{p} - y_{j}^{p}) \cdot f_2^{'}(S_j) \cdot w_{jk} \cdot f_1^{'}(S_k) \cdot x_i
\end{equation}

综上所述，可以用以下公式来表示隐含层的每一个神经元的连接权系数调整：
\begin{equation}
\Delta v_{jk} = \sum_{p=1}^{P} \sum_{j=1}^{m} \eta (t_{j}^{p} - y_{j}^{p}) \cdot f_2^{'}(S_j) \cdot w_{jk} \cdot f_1^{'}(S_k) \cdot x_i
\end{equation}

\subsubsection{BP算法的步骤}

上一节主要介绍了BP算法的基本原理，下面将简要介绍BP算法的具体步骤。 \par

BP算法的具体步骤如下：

\begin{itemize}
\item [1)]
权值初始化：随机地给 $w_{mi}(0)$、$w_{ij}(0)$、$w_{jp}(0)$ 赋值一组较小的非零数值。
\item [2)]
确定BP神经网络地结构参数并给出相关变量的定义：设输入向量为 $X_k = [x_{k1},x_{k2},...,x_{km}],(k=1,2,...,n$，该网络的训练样本的个数为 $n$。$Y_k(n)=[y_{k1}(n),y_{k2}(n),...,y_{kp}(n)]$ 为BP神经网络进行第 $n$ 次迭代后的实际输出。$d_k = [d_{k1},d_{k2},...,d_{kp}]$ 为期望得到的输出。
\item [3)]
输入训练样本：依次输入训练样本集 $X=[X_1,X_2,...,X_p]$，假设这次学习的样本为 $X_k(k=1,2,...,n$。
\item [4)]
正向传播过程：根据给定的训练模式输入，计算出网络的输出模式，并将其与期望模式进行比较，如果存在误差就执行 $(5)$；否则返回 $(6)$
\item [5)]
反向传播过程：a、计算同一层单元的误差；b、修正权值和阈值；c、返回 $(3)$，如果误差满足要求，则执行 $(6)$。
\item [6)]
训练结束。
\end{itemize}

\subsection{本章小结}

本章概述了BP神经网络的基本概念和工作原理，并详细阐述了它所使用的算法。在这章中首先对BP神经网络的拓扑结构进行了详细的描述，并在此基础上对它的学习过程做了进一步的解析；其次BP概述了神经元的基本原理；最后根据BP神经元的基本原理推导出了BP算法的基本工作原理，并对BP算法的训练过程进行了总结。

\section{BP神经网络算法的缺陷及改进方向综述}

\subsection{BP算法的优缺点}

标准BP网络模型把训练样本的输入输出问题转变为了一个有关非线性的数学优化问题。根据Widrow-Hoff规则，BP算法在学习算法方面使用了最速下降算法，并且对问题尤其是应用问题具有很强的识别功能。由于强大的通用性，识别和控制非线性系统的功能强大，BP算法成为应用最为广泛的人工神经网络之一。理论上来讲，BP神经网络对于任意复杂的非线性模型仿真，它的误差都可以达到任意小的程度；根据不同的具体情况，BP网络可以任意的设定网络的中间层数、各层的节点数及网络的学习速率等参数，由此可见，BP神经网络具有较大的灵活性。 \par

由分析可知，\textbf{只要BP神经网络的隐含层层数或者隐含层的神经元节点数足够多，那么网络就可以完成对任意非线性映射的逼近}。BP算法的学习算法是一个全局逼近的优化算法，因此它具有良好的泛化能力和较强的容错性。但是其仍存在以下缺陷： \par

\begin{itemize}
\item [1)]
\textbf{收敛速度慢。}在学习过程中，学习速率的收敛情况比较慢。尤其是网络的训练到达了一定程度后。举例来说，当误差下降到一定程度后，网络经过8000次训练，可能在这个过程中累加得到的误差下降量还不到0.001。此外，标准BP算法在误差下降时，难免会产生振荡的现象，这会严重影响网络的收敛速度。对于某些复杂问题，BP算法可能要进行几个小时甚至更长时间的学习训练。
\item [2)]
\textbf{目前仍没有给出网络隐含层层数和网络层节点数选取的理论指导}，只能根据实际经验来估计，然后在实践的过程中慢慢调整，在实际应用中，遵循着不同的结构确定原则，验证所选结构的合理性又需要大量的仿真实验。正因为如此，BP网络有时候并不能取得最佳的设计。一方面在网络过大时，容易产生学习效率低下或者过拟合导致容错性下降的问题；另一方面如果网络太小，则误差函数有可能不存在收敛性。
\item [3)]
\textbf{BP网络的学习误差在下降过程中常常会处于停滞状态。}即在学习过程中，很容易陷入局部极小值。BP网络是沿着一个局部的方向来逐渐改善网络的极值，然后希望使输出的误差函数达到最小化的一组全局解，但最终得到的往往只是极小值。
\item [4)]
\textbf{BP网络是一种有导师的学习网络，因此它需要外部提供确定的信息来指导网络的学习和训练}，也就是和输入样本一起提供的输出期望。同时，最速下降法为了能求出正确的梯度，一个最基本的要求就是激活函数和误差函数必须是可导的。有时候对于一些不方便得到输入模式的目标输出而只能获得网络综合行为的反应，使用阈值函数就可以很好的解决这些问题，然而函数可导性这一条件产生了很多限制。
\item [5)]
\textbf{BP网络的学习过程中，其记忆具有一定的不稳定性。}所谓记忆，就是用同一个神经网络进行学习模式 $A$ 的训练后，再进行学习模式 $B$ 的训练，连接权中能同时保存$A$ 和 $B$ 的信息。不同于人脑每次学习新知识后对原来知识的记忆没有太大的影响。BP神经网络在切换到新的学习模式后，其本来训练好的连接权系数已经被打乱，导致关于旧的学习模式的记忆消失。
\end{itemize}

\subsection{BP算法的改进方向}

由上述缺陷可知，在实际应用的过程中，表示BP神经网络已经不能很好的胜任，无法在良好的效率下执行解决实际的复杂问题。本章节将从网络中隐含层的层数、每一层中神经元的节点数、网络的学习速率、连接权系数的初始值、期望误差和激活函数等几个方面入手，谈谈关于标准BP神经网络算法的改进。

\subsubsection{网络的层数}

1989年已经由Robert Hecht-Nielson给出证明： \textbf{如果BP神经网络的隐含层含有足够多的神经元节点，那么该网络只需要含有一个隐含层即可实现对任何有理数函数的逼近}。因此，一个包含输入层，隐含层，输出层的三层BP神经网络便可以完成任意的非线性映射，且可以是任意的 $n$ 维到 $m$ 维。 \par

然而尽管理论上单隐含层可以解决问题，但是单层神经网络的误差较高且辨识度较低；提升网络的层数可以降低误差的同时提高辨识精度，但同时又会使得网络复杂化，不仅提高了网络的训练时间，还会产生过拟合的问题。事实上，如果只想要提高误差精度，我们也可以通过增加每一层的节点数来实现这一要求，其次，也更容易观察和调整BP神经网络的训练效果。所以在一般情况下，\textbf{我们首先考虑的是增加隐含层中的结点数，而不是隐含层的层数。}

\subsubsection{隐含层节点数}

输入层的神经元节点数主要取决于输入矢量的维数，因为这一层接受外部输入的数据，所起的作用是数据缓冲存储作用。 \par
输出层的神经元节点数主要取决于两个方面：一个是输出数据的数据类型，另一个是表示该类型所需数据的大小。 \par

而隐含层的神经元节点数，一般都是根据前人设计所得经验，并根据自己相关的实验来进行确定的。在一般情况下，影响隐含层节点数的方面大体有两个，一个是问题的求解要求，另一个是输入与输出的单元数。通常来说，要尽量的减少隐含层的节点数，只要隐含层能够正确反映出输入和输出的关系就可以了，只有这样才能使网络的拓扑结构简单明了。然而，网络从训练中获取信息的能力与隐含层的节点数有关，隐含层的节点数越多，网络获取信息的能力就越强；而且隐含层的节点数越少，就越不能成功的逼近目标函数；另一方面，如果隐含层节点数量太多，不但会增加训练的复杂度，还会使网络在训练过程中出现一些非相干的因素影响整个网络，造成一种“过度吻合”的现象。 \par

所以，隐含层的设计必须要综合考虑多个方面的因素。一般在具体设计中，首先网络只选择一个隐含层，当网络性能不再随着隐含层节点数的增加而得到较好改善，那么接下来就转换到对隐含层的层数的增加，在增加隐含层层数的同时要适当的减少隐念层的节点个
数，直到能获得一个满意的效果为止。如果要提网络的训练精度，可以应用这样一个方法，这个方法是只釆用一个隐含层然后逐渐增加隐含层的结点个数。这样的设计，在网络拓扑结构方面，它的实现要比增加隐含层的层数要简单很多。

尽管现在仍没有理论来确定一个网络的隐含层需要多少个神经元节点，但是下面的两个公式均可用于确定初始值：

\begin{equation}
l = \sqrt{m+n} +a
\end{equation}

\begin{equation}
l = \sqrt{0.43mn + 0.12n^2+ 2.54m^2+0.77n+0.35m+0.51}
\end{equation}

上述两式中， $m$ 为输入层的节点数目，$n$ 为输出层的节点数目，$a$ 是一个常数，其范围为$(-1,0)$。 \par

由此我们可以得到一个实践可行的方案，首先根据上述两个公式中的任意一个得到一个初始值 $l$，然后利用逐步修剪法（从一个比较复杂的神经网络开始，一步一步的删除隐含层节点单元，直到网络达到最佳为止）或逐步增长法（从一个比较简单的神经网络开始，如果不符合问题要求则增加隐含层节点数，直到网络达到最佳为止）来最终确定隐含层的节点数。

\subsubsection{初始权值}

BP神经网络的神经元的连接权系数会影响目标函数的收敛性以及它的收敛速度。这是因为BP神经网络算法系统研究的是非线性问题，所以，连接权系数的初始值会直接影响误差函数是否能够收敛，收敛后是否收敛于局部最小值以及影响训练完成的时间等等。如果连接权系数的初始值太大，将会使加权求和后的输入值落在激活函数的饱和区，从而导致激活函数的导数过小，产生梯度消失（Gradient disappearance problem）的问题。 \par

由计算权值的修正公式可知，当 $\delta \propto f'(n)$，$f'(n) \to 0$ 时，将有$\delta \to 0$，并导致 $\Delta w_{ij} \to 0$，从而使得连接权调整的过程几乎停止。因此，一般都希望连接权系数在加权求和后的输出值总是接近于 $0$，这样可以保证加权求和后的输出值不会落在激活函数的平坦区（靠近 $-1$ 或者靠近 $1$ 的部分），可以根据其变化对连接权系数进行最大的调节。经分析，连接权系数的初始值一般取 $(-1,1)$ 或者 $(0,2)$ 之间的随机数。

\subsubsection{学习速率}

学习速率的选择在BP神经网络的学习中起着至关重要的作用，学习速率能够决定连接权系数在每一次循环中产生的变化量的大小。如果训练时将学习速率取得过大，系统有可能因此变得不稳定甚至瘫痪；反之如果学习率取的过小，系统收敛缓慢，训练的时间显著增加。通常来说，首先要确保的是神经网络的稳定性，避免让其收敛到局部乃至发散，因此通常会选择一个较小的学习速率，算法中的学习速率一般选择在 $[0.01,0.8]$ 的范围内。

\subsubsection{期望误差}

期望误差是衡量系统的一个标准，通常定义为一个映射到实数的损失函数。若希望系统的误差能够达到比较小的数量级，就需要更多的隐含层节点和更多的训练时间。为了给网络一个合理的期望误差，需要对系统进行一些对比训练。 \par

神经网络应用的误差函数主要有三种： \par

\begin{itemize}
\item [1)]
在标准BP神经网络算法中使用的误差函数为： \par
\begin{equation}
E_p = \frac{1}{2} \sum_{j=1}^{m} (t_j^p - y_j^p)^2
\end{equation}
每一个训练样本输入后，都会对连接权系数矩阵进行修改。因为对连接权系数矩阵的每一次修改，都不会考虑权值被修改了以后，其它训练样本输入后产生的输出误差是否也能相应的减小，所以这一方法极大可能在不同样本的误差之间振荡，增加运算的迭代次数。

\item [2)]
累计误差BP算法是一个全局误差函数，定义为： \par
\begin{equation}
E = \frac{1}{2} \sum_{p=1}^{P} \sum_{j=1}^{m} (t_j^p - y_j^p)^2 = \sum_{p=1}^{P} E_p
\end{equation}

这一误差函数的设计目的是综合所有样本的误差，即全局误差，而不是特意针对某个训练的样本集。然而上式中，$m$ 和 $P$ 的大小会对误差的绝对值产生影响，所以不同的网络之间如果网络规模或者样本规模不同，就无法进行比较。

\item [3)]

BP网络的均方误差函数定义如下： \par

\begin{equation}
MSE = \frac{1}{mP} \sum_{p=1}^{P} \sum_{j=1}^{m} (\hat{y}_{pj} - y_{pj})^2
\end{equation}

其中 $m$ 是输出端的节点个数；$p$ 是训练样本集的总体数目；$\hat{y}_{pj}$ 是导师信息，即网络的期望输出，$y_{pj}$ 是网络输出端的实际输出值。均方误差几乎克服了上述两种误差函数的缺点，因此在网络的训练中大多数情况下都会选择均方误差函数 $MSE$。

\end{itemize}

\subsubsection{激活函数}

有关激活函数的有关信息在上文中已被多次提到。BP神经网络的神经元必须使用一个处处可导的激活函数。BP神经网络通常会设置一个或者多个隐含层，这些隐含层基本上把Sigmoid型函数作为神经元节点的激活函数，这是因为Sigmoid型激活函数是连续可导函数，它的这个特性也决定了它与感知器中的线性阈值函数的不同，因为阈值函数里然可导但不连续。 \par

和隐含层不同，输出层的各个神经元常采用线性的激活函数。这主要是因为整个网络可以取任意一个输出值，如果在输出层中使用Sigmoid型激活函数，那么整个网络的输出都将被限制在 $(-1,1)$ 的狭小范围中。 \par

Sigmoid 型激活函数有两个，一个是 log-sigmoid 函数，另一个则是 tan-sigmoid 函数，这两个函数能分别将训练样本的 $(-\inf, + \inf)$ 的输入值映射到区间 $(0,1)$ 和 $(-1,1)$ 中。激励函数分为单极性激励函数和双极性激励函数，其中单极性激励函数的典型代表是 log-sigmoid 函数，双极性函数的典型代表是 tan-sigmoid 函数。在优化算法中经常使用的双曲正切函数就是 tan-sigmoid 函数。 \par
从数学方面讲，双曲正切函数是一个连续可导的函数，它的导数为 $\mathbf{sech}(x)^2$。基于此，Surender K Kenue 提出了一阶导数为 $\mathbf{sech}(x)^n, n=1,2,...,n$ 的一簇函数，由于它们的性质和双曲正切函数的性质非常相似，所以完全适合作为激活函数。 \par

log-sigmoid 函数和 tan-sigmoid 函数可用下述方程来表示： \par


\begin{equation}
f_1(x)=\frac{1}{1+e^{-x}}
\end{equation}

\begin{equation}
f_2(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
\end{equation}

易知 $f_1(x) \in (0,1)$，$f_2(x) \in (-1,1)$，它们的导数定义为：

\begin{equation}
f_1'(x)=\frac{e^{-x}}{(1+e^{-x})^2} = f_1(x) \cdot [1-f_1(x)]
\end{equation}

\begin{equation}
f_2'(x)= \frac{4}{(e^x+e^{-x})^2} \mathbf{tanh}(x) = \mathbf{sech}(x)^2
\end{equation}

在实际应用当中，激励函数的选择要根据具体情况进行，基本上，这个选择主要根据输入和输出之间的关系定来下：如果输出值不会含有一些负值，那么网络可以采用 log-sigmoid 函数；反之如果输出中含有一部分负值，那么激活函数要采用 tan-sigmoid 函数。 \par

在当前实际的应用中，使用最为广泛的激活函数是双曲正切函数。一般情况下，如果隐含层的单元个数较少，那么导数阶数的 $n$ 可以选择的小一点，反之 $n$ 可以选择的大一点。\textbf{这些激活函数的性质恰恰反映了整个网络的输入与输出之间的关系，同时也是人工神经网络中非线性映射能力的来源。}

\subsection{改进的BP算法}

前文介绍了BP算法的缺陷，并引出了一些改进的方向。接下来介绍的是已有的多种改进BP算法，它们大体分为两大类：一类是启发学习算法，另一类是数值优化方法。其中，自适应学习速率法、弹性BP算法、附加动量法等改进方法属于前者，而共轭梯度法、拟牛顿算法、L\_M算法等改进属于后者。 \par


\subsubsection{自适应学习速率法}

由上一节关于学习率的分析可知，过低或者过高的学习率都容易对学习过程产生不好的影响，但低和高在学习过程中又是相对的概念。在 BP 神经网络的学习过程中，固定的学习率难以适应权重调整的多变要求。学习率过小时，算法收敛速度极慢；学习率过大时，网络每次的修正量也随之增大，权重容易越过梯度方向的最优值，产生永不收敛或者引起振荡的情况。为了克服上述缺陷，应该采用灵活多变的学习率进行学习。学习率自适应算法的核心思想是：\textbf{保证 BP 神经网络能选用学习率允许范围内的最大值进行学习。} 其实现数学公式如下所示： \par

\begin{equation}
\eta(n)=\begin{cases}
a \times \eta (n-1), E(n) < E(n-1) \\
b \times \eta (n-1), E(n) > c \times E(n-1) \\
\end{cases}
\end{equation}

\begin{equation}
w(n) = w(n-1) - \eta(n) \times \frac{\partial E(n)}{\partial w(n)}
\end{equation}

其中 $\eta(n)$ 是第 $n$ 次迭代的学习率，$E(n-1)$ 和 $E(n)$ 是前后两次误差函数的数值。$a$，$b$，$c$ 均为常数。推荐的取值范围分别为 $(1,2)$，$(0,1)$，$[1,1.1]$。在学习率自适应算法中，根据相邻两次误差函数值的大小关系动态调整学习率 $\eta(n)$。当新误差 $E(n)$ 小于旧误差 $E(n-1)$ 时，说明误差正在减小，将学习率扩大到原来的 $a$ 倍，加快收敛的速度；当新误差 $E(n)$ 大于旧误差 $E(n-1)$ 时，说明误差正在增大，也就是权重在此次的调整中被过调整，应立即缩小学习率到原来的 $b$ 倍，避免越过次梯度方向上的最佳权重。

\subsubsection{附加动量法}

附加动量法是在 BP 神经网络的反向传播阶段，将本次学习的理论权值调整量与上次权值调整量的一部分叠加到一起，作为本次学习的实际权值调整量，如下公式所示： \par

\begin{equation}
\Delta w(n+1) = m_c[w(n) - w(n-1)] - (1-m_c) \eta \nabla f(w(n))
\end{equation}

其中 $n$ 为训练次数， $m_c$ 为动量系数， $\eta$ 为学习率， $m_c \in [0,1]$。 \par

此算法的实质是将上次权值变化的影响通过动量因子 $m_c$ 传递到此次调整中。当 $m_c$ 的取值为零时，权重完全按照梯度下降法调整。当 $m_c$ 的取值为 $1$ 时，新的权重调整量等于上次权值的变化，而梯度下降法产生的调整量被直接忽略掉了。因此当加入动量项后，当网络权值进入误差曲面底部的平坦区域时，$\nabla f(w(n))$ 将变得很小，于是 $w(n+1) \approx w(n)$，从而防止 $w(n+1) = 0$ 的出现，有助于网络误差跳出局部极小值。\par

引入动量项后，BP 算法沿误差曲面的平均方向调整权重，而不单单按照负梯度方向更新权值。这种权重的调整方法，可以有效地越过网络的局部极小值点，减缓误差的反复震荡。权重在每次迭代中都向着合理的方向改变，算法的稳定性得到很大程度地加强，因此 BP 网络可以使用更高的学习率进行训练，加快了学习的步伐。但在实际运用中，如何选择最佳的动量系数，成为又一个难题。 

\subsubsection{弹性BP算法}

1993 年德国 Martin  Riedmiller 和 Heinrich  Braun 发现偏导数的大小对调整权重存在不利的影响，如果梯度数值过小，则权重的调整量有可能为 $0$。在论文《The RPROP Algorithm》里，他们提出在多层感知器中实现有指导批处理学习的局部自适应学习方案。为了消除梯度数值在权值调整中的作用，这种方法仅仅将梯度的符号作为权更新的方向，权值改变的大小由更新值 $\Delta_{ij}^{(n)}$ 来确定，具体公式如下：

\begin{equation}
\Delta w_{ij}^{(n)}=\begin{cases}
-\Delta w_{ij}^{(n)},\frac{\partial E^{(n)}}{\partial w_{ij}} > 0 \\ \\ 
+\Delta w_{ij}^{(n)},\frac{\partial E^{(n)}}{\partial w_{ij}} < 0 \\ \\
\Delta w_{ij}^{(n-1)},\frac{\partial E^{(n)}}{\partial w_{ij}} = 0
\end{cases}
\end{equation}

其中 $\frac{\partial E^{(n)}}{\partial w_{ij}}$ 表示误差函数曲面的梯度方向， $n$ 表示当前迭代的次数。 \par

如果导数为正，权重根据更新值 $\Delta_{ij}^{(n)}$ 减少；如果导数为负，权重根据更新值 $\Delta_{ij}^{(n)}$ 增加。更新值 $\Delta_{ij}^{(n)}$ 的计算方法如下式所示：  \par

\begin{equation}
\Delta_{ij}^{(n)}=\begin{cases}
\eta^{+} \times \Delta_{ij}^{(n - 1)}, \frac{\partial E^{(n-1)}}{\partial w_{ij}} \times \frac{\partial E^{(n)}}{\partial w_{ij}} > 0 \\ \\
\eta^{-} \times \Delta_{ij}^{(n - 1)}, \frac{\partial E^{(n-1)}}{\partial w_{ij}} \times \frac{\partial E^{(n)}}{\partial w_{ij}} < 0 \\ \\
\Delta_{ij}^{(n - 1)}, \frac{\partial E^{(n-1)}}{\partial w_{ij}} \times \frac{\partial E^{(n)}}{\partial w_{ij}} = 0
\end{cases}
\end{equation}

其中 $0 < \eta^{-} < \eta^{+}$，一般情况下，$\eta^{-} = 0.5$，$\eta^{+} = 1.2$。当前后两次误差的梯度方向相反时，说明前次更新值过大， 通过 $\eta^{-}$ 减小学习率，保证此次权重向合理方向调整。当前后两次误差的梯度方向相同时，可以通过 $\eta^{+}$ 增大学习率，加快权重的更新速度。 \par

在弹性 BP 算法中，当网络训练发生震荡时，权值的变化量将减小。当权值在连续几次迭代中朝一个方向搜索时，变化量将增大。这种算法可以规避梯度值大小的不确定性，因此往往可以准确地调整权重。但计算的消耗较大。

\subsubsection{共轭梯度法}

为了减小 BP 神经网络的训练误差，将搜索方向指向性能函数的函数值不断减小的方向，即性能函数负梯度方向。然而大量的实验结果表明，原始梯度下降法收敛的速度非常慢，且易于陷入局部极小。共轭梯度算法认为权值在假定解范围内的误差函数能够用一个二次型函
数来准确近似。该算法只应用误差函数的一阶导数值，然后将前后相邻两次的搜索方向线性组合，利用这种具有共轭特性的新向量作为方向向量进行逐步的搜索。共轭梯度算法的数学实现过程如下。 \par

\begin{equation}
\mathbf{Target Function} = \mathbf{min} E(w), w \in R
\end {equation}

若误差函数的最小值可以按照梯度方向 $d(n)$ 逐步搜索得到，即： \par

\begin{equation}
E(w(n) + \eta_{n}d(n)) = \mathbf{min} E(w(n+1))
\end {equation}

则有： \par

\begin{equation}
w(n+1) = w(n) + \eta_{n}d(n)
\end {equation}

\begin{equation}
d(n) = -g(n) + \beta_n d(n-1), d(0) = -g(0)
\end {equation}

式中 $g(n)$ 是误差函数的梯度方向。初始迭代时，$d(0)=-g(0)$。$A$ 是误差函数的正定 Hessian 矩阵。搜索步长 $\eta_n$ 和方向因子 $\beta_n$ 可以按照下述两个公式计算： \par

\begin{equation}
\eta_{n} = - \frac{g^{T}(n) d(n)}{d^{T}(n) Ad(n)}
\end {equation}

\begin{equation}
\beta_{n} = - \frac{g^{T}(n) g(n)}{g^{T}(n-1) g(n-1)}
\end {equation}

共轭梯度法的基本思想是：将第  $n$ 次迭代搜索方向 $d(n)$ 指向第 $n$ 次迭代时的最速下降法方向 $\nabla E(w)$ 与 $n-1$ 次迭代搜索的方向 $d(n-1)$ 的线性组合，且 $d(n)$ 与 $d(n-1)$ 是共轭向量。对于 BP 神经网络，由于均方误差函数无法导出二次型函数，因此需要对原有共轭梯度算法进行修正。修正 BP 算法的学习过程如下： \par

\begin{itemize}
\item [1)]
网络初始化。令 $n = 0$，设置学习率上限 $C > 0$ 和优化目标 $\epsilon > 0$，随机生成初始权值序列 $w(0)$。
\item [2)]
通过局部梯度 $\delta (0)$，计算梯度 $g(0) = \nabla E(w(0))$
\item [3)]
选择搜索方向 $d(0)$，$d(0) = -g(0)$
\item [4)]
计算学习率 $\eta_n$，采用一维搜索选择 $\eta_n$ 使得下式成立：
\begin{equation}
E(w(n) + \eta_n d(n)) = \min \limits_{0 \le \eta \le C} E(w(n) + \eta d(n))
\end {equation}
\item [5)]
调节BP网络参数
\begin{equation}
w(n+1) = w(n) + \eta_n d(n)
\end {equation}

\item [6)]
置 $n = n + 1$

\item [7)]
若$E(w(n)) < \epsilon$，算法终止。

\item [8)]
通过计算局部梯度 $\delta(n)$，计算梯度 $g(n) = \nabla E(w(n))$。

\item [9)]
计算方向因子 

\begin{equation}
\beta_n = \frac{\left\lVert g(n) \right\rVert^2}{\left\lVert g(n-1) \right\rVert^2}
\end{equation}

\item [10)]

计算方向 $d(n)$：若 $n < N$ （$N$ 为BP算法的迭代上限），则 $d(n) = -g(n) + \beta_n d(n-1)$，并转到步骤 $(4)$；否则，$n > 0$，$w(0) = w(n)$ 和 $g(0) = g(n)$，并转到步骤 $(3)$。

\end{itemize}

当 $g^T(n-1) \times g(n-1)$ 很小时，$\beta_n$ 的计算过程中会出现因舍入误差较大而导致 BP 算法不稳定的现象，并且该算法在搜索过程中的计算量较大。针对该算法的学习缺陷，一些优化共轭梯度算法的学习过程被提出。例如：Powell-Beale 共轭梯度法，将共轭梯度法和拟牛顿法折中的一步割线法，成比例的共轭梯度法，改进的共轭梯度法与不精确的线性搜索相结合的 BP学习算法，简单共轭梯度学习算法，基于改进共轭梯度法的快速监督学习算法，最速下降—共轭梯度(SD-CGM)算法等。 \par

梯度下降法有收敛速度慢的缺点，拟牛顿法的计算则较为复杂，而共轭梯度法则试图避免两者的缺点。共轭梯度法不必计算或储存误差函数的二阶导数信息，然而却具有二阶收敛特性。此算法需要的内存空间较少，不必计算中间矩阵，与拟牛顿法相比算法复杂性略有降低。 


\subsubsection{拟牛顿法}

拟牛顿法是一种改进 BP 算法的常见数值优化方法，它的理论基础是牛顿法（Newton's method）。其基本思想是用一个二次函数去局部近似性能函数 $f(x)$，然后求出近似函数的极小点。其迭代公式为：

\begin{equation}
x(n+1) = x(n) - \eta_n(H(n))^{-1} \nabla f(x(n))
\end{equation}

其中 $\nabla f(x(n))$ 是性能函数 $f(x)$ 在 $x(n)$ 处的梯度向量，$H(n) = \nabla^2 f(x(n))$ 是性能函数 $f(x)$ 在 $x(n)$ 处的二阶梯度矩阵，即 Hessian 矩阵。理论分析表明，牛顿法至少需要二阶才能收敛，对于BP神经网络，确定误差函数 $E(w(n))$ 的 Hessian 矩阵十分困难。拟牛顿算法理论上使用误差函数的二阶曲率信息，但实际上不要求得到 Hessian 矩阵。它通过前后两次迭代
的权重变化量 $\Delta w(n)$ 和梯度向量 $g(n)$ 的变化量 $q(n)$ 来实现。具体过程如下： \par

拟牛顿算法的权值更新公式为： \par

\begin{equation}
w(n+1) = w(n) + \eta_n d(n) 
\end{equation}

\begin{equation}
d(n) = -S(n) g(n)
\end{equation}

其中方向向量 $d(n)$ 用梯度向量 $g(n)$ 来定义，矩阵 $S(n)$ 是每次迭代中调整的正定矩阵，目的在于让方向向量 $d(n)$ 逼近牛顿法的方向 $\{ H(n) \} ^{-1} \times \nabla f(x(n))$。 \par

令：

\begin{equation}
q(n) = g(n+1) - g(n)
\end{equation}
\begin{equation}
\Delta w(n) = w(n+1) - w(n)
\end{equation}

在逼近的条件下，下式可以成立：

\begin{equation}
q(n) \approx (\frac{\partial g(n)}{\partial w}) \times \Delta w(n)
\end{equation}

用 $S(n)$ 去逼近 $H(n)$，则有：

\begin{equation}
S(n) \approx H(n) = (\frac{\partial g(n)}{\partial w}) \approx q(n) \times \Delta w^{-1}(n)
\end{equation}

当误差函数是二次函数时，上述公式是精确的。通过上述公式的代换过程，拟牛顿算法实现了对 Hessian 矩阵 $H(n)$ 的逼近。对于 $H(n)$ 的近似矩阵 $S(n)$ 可以根据上式使用递归的方法得到： \par

\begin{equation}
S(n+1) = S(n) + \frac{\Delta w(n) \Delta w^T(n)}{q^T(n) q(n)} - \frac{S(n) q(n) q^T(n) S(n)}{q^T(n) S(n) q(n)} + \epsilon(n)[q^T(n) S(n) q(n)][v(n)v^T(n)]
\end{equation}

其中，

\begin{equation}
v(n) = \frac{\Delta w(n)}{\Delta w^T(n) \Delta w(n)} - \frac{S(n)q(n)}{q^T(n)S(n)q(n)}, 0 \le \epsilon \le 1
\end{equation}

由上述的数学推导可知，拟牛顿算法实现了对 Hessian 矩阵的逼近，拥有了二维的搜索速度。当上式中参数 $\epsilon(n)$ 的取值不同时，逼近 Hessian 矩阵的方法不同，比较典型的是\textbf{ DFP 拟牛顿法} 和 \textbf{BFGS 拟牛顿法}：

\begin{itemize}
\item [1)] 当所有 $n$ 满足 $\epsilon(n) = 0$ 时，得到 Davidson-Fletcher-Powell 算法，即 DFP 拟牛顿法，这是拟牛顿法的基本形式。
\item [2)] 当所有 $n$ 满足 $\epsilon(n) = 1$ 时，得到 Broyden-Fletcher-Goldfarb-Shanno 算法，即 BFGS 拟牛顿法，这是目前拟牛顿法的最好形式。
\end{itemize}

拟牛顿法是一种常见的数值优化方法，其收敛速度比一阶梯度算法快。拟牛顿法在搜索方向上较梯度法有改进，它不仅利用误差函数在搜索点的梯度，而且还利用了它的二阶导数矩阵。然而，在计算机编程仿真过程中，BP 神经网络需要对 Hessian 矩阵逼近计算，算法的复
杂性增加。

\subsubsection{Levenberg-Marquardt(LM)算法}

LM 算法源于牛顿法和梯度下降法，为了将牛顿算法应用于 Hessian 矩阵非正定的情形，此算法试图通过计算正定矩阵来避免计算Hessian 矩阵。在学习BP神经网络时，LM 算法采用比例因子 $\mu$ 来控制权重调整的大小，有效地加快了网络的学习速度。与此同时，二维搜索方式对抑制网络陷入局部极小的效果也十分明显。LM 算法的数学推导过程如下。 \par

对于牛顿法，令 $\nabla E(w(n))$ 代表误差函数的一阶梯度，$H(n)$ 代表二阶 Hessian 矩阵，权重的变化量为：

\begin{equation}
\Delta w(n) = - \eta_n \{ H(n) \}^{-1} \nabla E(w(n))
\end{equation}

对于BP神经网络，令 $i = 1,2,...,N$ 为样本数，误差函数为：

\begin{equation}
E(w) = \frac{1}{2} \sum_{i=1}^{N} e_{i}^{2} (w)
\end{equation}

\begin{equation}
\nabla E(w(n)) = J^T(w)e(w)
\end{equation}

\begin{equation}
H(n) = J^T(w)e(w) + S(w)
\end{equation}

其中，$S(w)=\sum_{i=1}^{N} e_i(w) \nabla^2 e_i(w), J = [\frac{\partial e_i(w)}{\partial w_j}]_{i,j}$,$J$ 为 Jacobin 矩阵。 \par

\begin{equation}
J = \begin{bmatrix}
\frac{\partial e_1(w)}{\partial w_1} & \frac{\partial e_1(w)}{\partial w_2} & ... & \frac{\partial e_1(w)}{\partial w_n} \\\\
\frac{\partial e_2(w)}{\partial w_1} & \frac{\partial e_2(w)}{\partial w_2} & ... & \frac{\partial e_2(w)}{\partial w_n} \\\\
... & ... & ... & ... \\\\
\frac{\partial e_N(w)}{\partial w_1} & \frac{\partial e_N(w)}{\partial w_2} & ... & \frac{\partial e_N(w)}{\partial w_n}
\end{bmatrix}
\end{equation}

对于牛顿法，权值的调整量可归纳为：\par

\begin{equation}
\Delta w(n) = -\eta_n [J^T(w) J(w)] ^{-1} \times J(w)e(w)
\end{equation}

LM算法将牛顿法的权值调整改进为：

\begin{equation}
\Delta w(n) = -\eta_n [J^T(w) J(w) + \mu I] ^{-1} \times J(w)e(w)
\end{equation}

其中 $\mu$ 为大于 $0$ 的常数，$I$ 为单位矩阵。 \par

LM 算法根据学习结果动态调整阻尼因子，即动态调整收敛方向，保证误差在每次迭代中都有所下降。它是梯度下降法和牛顿法的结合，收敛速度非常快。但需要得到误差函数的二阶导数信息，算法的复杂度很大。在计算过程中会产生大量的中间结果矩阵，需要较大的计算机内存空间。 

\subsection{本章小结}

本章首先对BP算法的缺陷和不足进行了归纳和总结，然后分类描述了BP算法的改进方向。最后对当前出现的改进BP算法中的几种进行了详细的描述。本章对自适应学习速率法、附加动量法、弹性BP算法、共辄梯度法、拟牛顿法、L\_M算法这六种改进算法进行了描述，并归纳了这些算法的基本改进原理。

\section{BP神经网络算法的改进}

上文已经提到了标准BP神经网络的缺点和不足，并在几个方面对其做了论述，从学习速率、连接权系数的初始值、隐层节点数、网络层数、期望误差以及激活函数等方面为修改标准BP算法指出了方向。这一章主要是在这个基础上提出新算法，实现对标准BP算法的改进。

\subsection {BP算法的改进设想}

从上一章中可知，BP 算法的改进主要分为两类，一类是基于梯度下降方向的方法，如自适应学习速率法、附加动量法、弹性BP算法等；另一类是基于数值优化方面的方法，如共辄梯度法、拟牛顿法、L\_M算法等，这一类BP算法不仅能够增加算法的收敛性以减少网络的训练时间，还能够优化算法数值上的性能使其避免陷入全局最小，但其同样也有缺陷，就是在实现过程中一般需要一个 Hessian 矩阵，实现起来算法复杂度较大。 \par

假设BP网络使用的目标函数是 $\mathbf{min} E(w)$，该函数存在一阶偏导数且能在 $w'$ 处取到最小值。BP算法通过迭代来逐渐接近最小值 $w'$，假设 $w(m)$ 是算法对 $w'$ 的第 $m$ 次搜索后得到的接近值，并且假设其搜索的方向为 $d(m)$，它的搜索步长为 $\eta$，那么则有： \par

\begin{equation}
w(m+1)=w(m)+ \eta d(m)
\end{equation}

对 $E(w)$ 在 $w(m+1)$ 处作多元函数一阶泰勒展开：

\begin{equation}
E[w(m+1)]=E[w(m)+\eta d(m)]=E[w(m)] + \eta \nabla E[w(m)]^Td(m) + O(\eta)
\end{equation}

其中 $\nabla E[w(m)]$ 是 $E(w)$ 在 $w(m)$ 处求得的梯度（假设其不为 $0$），$\eta$ 为搜索步长，$O(\eta)$ 是 $\eta$ 的高阶无穷小。 \par

这时 $\nabla E[w(m)]^Td(m) < 0$，就会存在：

\begin{equation}
E[w(m+1)] < E[w(m)]
\end{equation}

结合泰勒展开处的公式，可得到下列不等式：

\begin{equation}
E[w(m) + \eta d(m)] < E[w(m)]
\end{equation}

为了能够使 $\nabla E[w(m)]^T d(m) < 0$ 满足成立的条件，就必须寻找梯度向量 $d(m)$ 使得该不等式的左边可以取得最小值。根据无约束数值优化方面的知识可知，负梯度的方向就是函数值下降最快的方向，沿着这一方向进行搜索就有较快达到极小值点的可能性。同时，要使得上述公式成立，还需要对学习步长 $\eta$ 进行试算。由上一章节可知，传统自适应学习率算法中，它的学习步长是通过下面的公式调整的：

\begin{equation}
\eta (m) = \begin{cases}
a \times \eta (m-1) ; E(m) < E(m-1) \\
b \times \eta (m-1) ; E(m) > c \times E(m-1)
\end{cases}
\end{equation}

上式中 $a$ 、$b$、$c$均为常数，取值范围分别为 $(1,2)$、$(0,1)$、$[1,1.1]$。 \par

在传统的自适应学习率算法中，$\eta(m)$ 表示在第 $m$ 次迭代中计算取得的调整某一层的搜索步长，其代表层与层之间的BP神经网络节点的连接权系数的改变量的大小。假设隐含层和输出层之间的连接权系数为 $w_{ip1},w_{ip1},...,w_{ipm}$。在进行误差反向传播的阶段，对于这个调整的过程，学习率 $\eta(m)$ 依然是很恒定的。虽然这个时候算法的学习速率会有一系列动态变化，能够加速误差函数的收敛速度，但是要做到同时满足不同权系数的优化是非常困难的。所以传统的自适应学习率算法还有进一步改进的空间。 \par

基于传统的自适应学习率算法和上述分析，本章接下来的部分将提出新的改进。在BP网络反向传播的过程中，如果神经元节点之间的连接权系数不同，我们则采用不同的学习速率进行寻优搜索。这么做以后，通过对不同神经元区别对待，进行有差别的调节，可以使得学习率的适应程度达到最大的限度，满足误差函数中不同组合部分的不同学习要求。经过改进之后，算法可以随机选取学习步长 $\eta$ 的起始值。新算法的学习步长不固定，会在对目标函数 $E(w)$ 的最小值逼近的过程中进行调整，具体如下式所示：

\begin{equation}
\begin{cases}
\eta (k+1) = m^{\lambda} \times \eta(k) \\
\lambda = \mathbf{sgn} [d(m) d(m-1)] \\
m \in R
\end{cases}
\end{equation}

其中 $m$ 为常数，通常的取值为 $2$ 或者 $3$； $\lambda$ 由符号函数确定，为 $-1$ 或者 $+1$。 \par

新算法学习步长的调整步骤如下，$\lambda > 0$ 时，即最近两次迭代前进的梯度方向一致，所以我们继续保持原来的搜索方向，并按下式增大原来的学习步长：

\begin{equation}
\eta(m+1) = m \times \eta(m)
\end{equation}

$\lambda < 0$ 时，最近两次迭代前进的梯度方向相反，我们需要在原来相反的搜索方向上逐步减小学习步长，才能令误差重新下降，新步长的计算方法如下式所示：

\begin{equation}
\eta(m+1) = \frac{1}{m} \times \eta(m)
\end{equation}

综上可得新算法的连接权系数调节公式：

\begin{equation}
\begin{cases}
\Delta W(m+1) = (1-m_c) \eta (m+1) \times d(m) + m_c \times \Delta W(m) \\
d(m) = - \frac{\partial E}{\partial W(m)} \\
\eta(m+1) = k^{\lambda} \eta (m) \\
\lambda = \mathbf{sgn} [d(m) d(m-1)] \\
\end{cases}
\end{equation}

其中 $m_c$ 为动量因子。新算法在附加动量法和适应学习率算法的基础上提出，因此其同时具有具有两个算法的优点；在误差函数梯度的平坦区，学习速率主要受到附加动量法的影响，不会因为梯度消失而停留在平坦区；反之当网络的输出结果和期望值相差甚远的时候，学习速率的决定量则是适应学习率算法，其能通过自适应步长使得算法以更快的收敛速率接近期望值。\par

下述给出标准BP算法和新算法的伪代码，通过比较可以容易看出两个算法之间的异同：

\begin{algorithm}
\caption{Standard BP Neural Network Algorithm}  
\label{alg: Standard BP Neural Network Algorithm} 
\begin{algorithmic} [1] 
\State $E, W, \eta, \hat{y}, p, q$
\While {$E > \hat{E}$}
	\For {$i = 1 \to p - 1$}
		\For {$j = 1 \to q - 1$}
			\State $d(m) \gets {\partial E} / {\partial W_{ij}(m)}$
			\State $\Delta W_{ij} (m+1) \gets \eta \times d(m)$
			\State $W_{ij} (m+1) \gets W_{ij} (m) + \Delta W_{ij} (m+1)$	
		\EndFor
	\EndFor
	\State $E \gets 0$
	\For {$p = 1 \to P$}
		\State $E \gets E + \frac{1}{2} (y_i - \hat{y}_i)^2$
	\EndFor
	\State $m \gets m + 1$
\EndWhile
\end{algorithmic}
\end{algorithm}

上式中 $\hat{E}$ 为目标函数的期望误差， $m$ 为网络运行的迭代次数；$\eta$ 为学习步长；$y_i$ 为网络实际输出， $\hat{y_i}$ 为网络期望输出。

\begin{algorithm}
\caption{New BP Neural Network Algorithm}  
\label{alg: New BP Neural Network Algorithm} 
\begin{algorithmic} [1] 
\State $E, W, \eta, \hat{y}, p, q$
\State $\beta \gets 2 $ \textbf{or} $3$
\While {$E > \hat{E}$}
	\For {$i = 1 \to p - 1$}
		\For {$j = 1 \to q - 1$}
			\State $d(m-1) \gets {\partial E} / {\partial W_{ij}(m-1)}$
			\State $d(m) \gets {\partial E} / {\partial W_{ij}(m)}$
			\If {$d(m)d(m-1) > 0$}
				\State $\eta(m+1) \gets \beta \times \eta(m)$
			\Else
				\State $\eta(m+1) \gets \frac{1}{\beta} \times \eta(m)$
			\EndIf
			\State $\Delta W_{ij} (m+1) \gets (1-m_c) \eta(m+1) \times d(m) + m_c \times \Delta W_{ij} (m)$
			\State $W_{ij} (m+1) \gets W_{ij} (m) + \Delta W_{ij} (m+1)$	
		\EndFor
	\EndFor
	\State $E \gets 0$
	\For {$p = 1 \to P$}
		\State $E \gets E + \frac{1}{2} (y_i - \hat{y}_i)^2$
	\EndFor
	\State $m \gets m + 1$
\EndWhile
\end{algorithmic}
\end{algorithm}

\newpage

\subsection {改进后算法的推理}

\newpage

设 $X$ 是网络的输入向量，$Y$ 是网络的输出向量， $U$ 是输入层到隐含层的系数矩阵，$V$ 是隐含层到输出层的系数矩阵。假设 $rsU$ 为矩阵 $U$ 的展开矩阵，$rsV$ 为矩阵 $V$ 的展开矩阵。样本总数为 $S$, $f(.)$ 为激活函数。$D_y$ 是期望输出，$E(n)$ 为误差函数。 \par

正向的传播过程在新算法中没有变化，主要变化的地方在误差的反向传播过程。设 $W$ 表示BP网络的所有权值矩阵，那么 $W = [rsU,rsV]$，因为算法是逆向调整矩阵，所以为了计算方便可假设 $W^* = [rsV,rsU]$。令$m$，$n$ 代表整体权值矩阵的列向量数目。当：

\begin{equation}
m = (I + 1) \times J + (J + 1) \times P
\end{equation}
\begin{equation}
n = (J+1) \times P
\end{equation}

时，$W^* = [rsV,rsU]=[w_1,w_2,...,w_n,...,w_m]$。逆序权值矩阵中的任意权值就可以表示为 $w_i,i \in [1,m]$。 \par

设 $W(n)$ 为BP神经网络第 $n$ 次学习后得到的权值矩阵， $W^*(n)$ 为其逆序矩阵，其初始值可以表示为 $W(0)$ 和 $W^*(0)$。\par

如果 $W(n)$ 在信息的正向传播过程中可以满足网络的学习终止条件 $E(n) \le e$，其中 $E(n)$ 是网络在第 $n$ 次学习时的误差， $e$ 为预制的精度值，那么 $W(n)$ 就是网络的最优权值矩阵；否则网络就会继续进入误差的反向传播阶段。调整方法以逆序矩阵中的任以权值 $w_i$ 为例（其梯度 $\frac{\partial E}{\partial w_i} \ne 0$： \par

\begin{equation}
\Delta W_{ij} (m+1) \gets (1-m_c) \eta(m+1) \times d(m) + m_c \times \Delta W_{ij} (m)
\end{equation}
\begin{equation}
W_{ij} (m+1) \gets W_{ij} (m) + \Delta W_{ij} (m+1)	
\end{equation}

假如 $w_i(n+1)$ 按正向传播计算，误差减小，那么则增大学习速率 $\eta$，然后再沿着 $w_i(n)$ 的负梯度方向按新的学习速率 $\eta_i(n)$ 重新计算 $w_i(n+1)$。首先，求得一个新的权值 $w_i^{(1)}(n+1)$，如果 $w_i^{(1)}(n+1)$ 经正向传播后计算所得到的误差减小，则继续增大学习速率，然后继续调整权值并计算新权值 $w_i^{(2)}(n+1)$，如果新得到的权值误差仍然减小，那么则按照上面的方法继续增大学习速率，调整权值，如果在第 $m+1$ 次计算后所得误差刚好不再减少，那么新的权值将为 $w_i^{(m-1)}(n+1)$，即：

\begin{equation}
w_i(n+1) = w_i^{(m-1)}(n+1)
\end{equation}
\begin{equation}
\eta_i(n) = \eta_i^{(m-1)}(n)	
\end{equation}

如果 $w_i(n+1)$ 在BP网络正向传播的过程中误差增大，那么学习速率则将要减小，表示为 $\eta_i(n) \gets \eta_i(n) / \beta$，并且再沿着该权值的负梯度方向利用新的学习速率计算新的权值，如果计算所得到的新权值依然不满足条件，即误差依然在增大，那么继续按照上面的方法计算学习速率，并计算新的权值。最终必定能得到一个权值 $w_i(n+1)$ 优于 $w_i(n)$。 \par

按照计算 $w_i(n+1)$ 的方法计算一遍所有节点间的连接权值，就是BP神经网络的一次学习过程。计算后我们可得一个全新的权值矩阵，并判断是否能满足迭代的终止条件。如果不满足，则返回前面的步骤继续进行迭代计算。

\subsection{本章小结}

本章提出了改进BP算法的设想，对其可行性进行了分析推导，并且在基于附加动量法和自适应学习率算法的基础上提出了本章的新算法，给出了和标准BP算法进行比较的伪代码，最后再次通过分析对其可行性进行了验证。

\section{总结}

在本文中，首先介绍了BP神经网络发展的简史，通过先介绍最基本的BP网络神经元，推导和分析了标准BP神经网络的原理。然后分析了标准BP神经网络的缺陷，针对各个缺陷的改进方向，以及前人提出的基于数值和基于梯度的改进方法，并细化介绍了其中的一部分方法。最后基于附加动量法和自适应学习率算法的基础上提出了另一种改进方法，介绍了其原理并分析了其可行性。

\end{document}

