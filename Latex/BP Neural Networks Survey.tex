\documentclass[UTF8]{ctexart}
\usepackage{color}
\usepackage{algorithm}  
\usepackage{algpseudocode}  
\usepackage{amsthm,amsmath,amssymb}
\usepackage{mathrsfs}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage{tikz}
\usepackage{verbatim}
\usetikzlibrary{trees}

\title{有关BP神经网络的分析及优化改进研究}
\author{余畅 \\ 2019091621002， 信息与软件工程学院}
\begin{document}
\maketitle

\section{摘要}
\textbf{关键词：人工神经网络，BP算法，最速下降法，算法改进} \par
人工神经网络（Artificial Neural Network，ANN ）是20世纪80 年代以来人工智能领域兴起的研究热点。人工神经网络所代表的，即是对人脑的神经元进行不同层次的抽象，使用不同的连接方法组成不同的网络，本质上来说就是一种\textbf{运算模型}。最近十多年来，人工神经网络的研究工作不断深入，在模式识别、预测估计、自动控制等领域都取得了较大的发展。随着研究的不断深入，卷积神经网络，图神经网络，细胞神经网络等算法相继出现。但无法忽视的是，\textbf{BP神经网络}虽然出现时间较早，算法构造相对简单，但其作为人工智能神经网络中的典型算法，其本身具有很强的非线性分类能力，在解决非线性的问题上能力突出。此外，BP神经网络的网络拓扑结构简单，因而具有较高的误差精度；其算法简单，可操作性强，易于编程实现。这些优点都使得BP神经网络成为智能领域的重要算法之一。 \par
然而标准的BP神经网络算法既有其优点，也有其局限性：标准BP神经网络使用最速下降法进行优化，收敛速度慢且很容易陷入局部最小点，产生学习能力不足的问题；标准BP神经网络的隐含层难以通过标准的方法给出所需的层数和每层神经元的节点数，容易产生过拟合和欠拟合的问题；标准BP神经网络是有监督的学习算法，其每一个输入模式都必须知道期望输出以及误差精度。这些缺陷导致标准BP神经网络算法参数过多，经验性较强，算法的学习能力依赖于不断地调参和试错。 \par
本文章旨在介绍标准BP算法的基本原理，结合其不同的缺点总结相应的改进方案，并通过应用改进后的新算法，验证新算法的可行性和鲁棒性。

\section{序言}
\subsection{背景}
人工神经网络是为了进行信息处理而建立的一种数学模型。它被称为神经网络是因为它是在现代神经科学研究成果的基础上提出的，通过一个个人工神经元模拟人类人类大脑神经突触连结形成的网络结构。它可以模仿人脑神经系统对外界信号接受、处理、储存的过程，具有强大的信息处理的能力。 \par
19世纪40年代初，心理学家Mcculloch和数学家Pitts从信息处理和数学建模的角度出发，通过研究信号在神经元之间进行传递的机制，提出了神经元的MP数学模型，随后无导师学习、感知器模型、反向传播算法、最小均方规则、模拟退火算法、竞争学习等等理论和算法也相继被提出。通过这些学习模型，神经网络的学习结构，处理各类信息的能力等都得到了改善，并得到了极大的发展：其具有非线性的映射能力，擅于从输入和输出信号中寻找规律，不需要进行精确的建模，从软硬件层面都易于实现，而且具有并行能力。人工神经网络解决问题的普适性和鲁棒性，使得其在模式识别，人工视觉，文本翻译，信号处理等领域展现出强大的能力。 \par
\subsection{BP神经网络简史}
1985年Rumelhart在\textbf{误差反向传播理论}的基础上提出反向传播（Back-Propagation）学习算法，即BP神经网络算法。BP神经网络构建在多层前馈网络的基础上，由输入、输出、隐含层组成。输入信号首先通过各个神经元激活函数的作用，在各层神经元之间层层传递，最终完成正向传播；接着根据正向传播得到的误差信号，BP神经网络利用梯度下降法进行有导师式的反向传播学习；在正向、反向学习反复不断进行的过程中，误差信号最终收敛到一个最小值。1988年Cybenko指出，当各个节点（即神经元）均采用Sigmoid型函数时，一个隐含层就足以实现任意的判决分类问题，两个隐含层则足以表示输入图形的任意输出函数。这反映出BP神经网络具有强大的数据识别和模拟能力，尤其是在解决非线性系统的问题的领域，主要有：模式识别、智能控制、图像识别、优化计算等等。 \par
\subsection{BP神经网络缺陷}
随着BP神经网络在多领域的广泛应用，BP算法自身存在的诸多问题也逐渐暴露出来：BP神经网络的收敛速度慢，导致学习的时间过长；学习过程中容易陷入局部极小值；网络的泛化能力差；构建网络结构缺乏统一原则等。缺陷产生的直接原因是BP神经网络自身的算法不完善，产生了算法精度差的直接后果，影响网络的学习速度，限制了网络的广泛运用。自从BP算法被提出之后，对于它的改进工作就一直在进行。本文希望能通过分析BP算法的原理之后，针对BP算法的不足，借鉴前人的一些实际运用的改进经验，进一步提出改进BP算法的新思路。

\section{BP神经网络的原理及方法}

\subsection{BP神经网络的基本原理}

作为人工神经网络中应用广泛的算法模型，BP神经网络具有完备的理论体系和学习机制。BP神经网络模仿人脑神经元对外部激励信号的反应过程，建立多层的感知器模型，并且不断地重复迭代信号的正向传播和误差的反向调节，通过这样多次的迭代学习，网络将自动调整收敛到最终的结果。

\subsection{BP神经网络的理论基础}

BP神经网络的结构基础是\textbf{单层感知器模型}，作为神经网络中的一个最小的单元，它试图模拟人脑神经元记忆、学习和认知的过程，采用阈值激活函数（Activation function）将一组输入向量映射到一个 $0$ 或是 $1$ 的目标输出。人脑的神经元形态各异，但是具有共性的部分，主要包括四个部分：细胞体、树突、轴突和突触。树突是细胞向外延伸出的数量较多的较短分支，可以接受其他神经元提供的脉冲信息，相当于细胞的输入端；轴突是细胞单一的向外伸出的最长分支，信息通过此传输到其他的神经元，相当于细胞的输出端。总结来说，\textbf{信息流从树突出发，经过细胞体，最终从轴突传出}。

1943年心理学家 McCelland 和数学家 W. Pitts 通过分析人脑神经系统结构，在此研究的基础上，提出了MP模型，BP神经元模型就是MP模型不断改进之后的结果。通常来看，构成BP神经元模型的三个要素是：

\begin{itemize}
\item [1)]
具有一组突触或连接。常用 $w_{ij}$ 表示神经元 $i$ 和神经元 $j$ 之间的连接强度（权值）。
\item [2)]
具有反映生物神经元时空整合功能的输入信号累加器。即将输入权值向量通过不同的权重累加映射为实数。
\item [3)]
具有一个激活函数用于限制神经元输出。激活函数通常将输出范围限制在 $[-1,1]$ 或者 $[0,1]$ 的实数域中。
\end{itemize}


\end{document}